---
title: Week14 Day66
tags:
  - BoostCamp-ai-tech
  - P stage
  - Week14
  - Done
  - To do
---

이번주는 강의가 없고 대회에 집중하면 된다.  
또한 멘토님이 배정되어 여러가지를 질문할 수 있게 되었다!  

### Done
- DeepLabV3  
backbone model로 VGG16을 사용했다.  
다음 이미지는 현재 가장 성능이 좋은 `DeepLabV2`와 비교한 것이다.  
   - train, validation loss  
   <img src="/assets/images/139.png" width="600px">  
   <img src="/assets/images/140.png" width="600px">  
   - train, validation mean IoU  
   <img src="/assets/images/141.png" width="600px">  
   <img src="/assets/images/142.png" width="600px">  

   이전까지 모델 중 가장 특이한 양상을 보였다.  
   중간에 갑자기 loss가 증가하는 모습을 보였다.  
   `DeepLabV3`의 public LB는 `0.5446`로 현재 가장 성능이 좋은 모델인 `DeepLabV2`의 public LB `0.5527` 보다 약간 낮다.  


### Week14
앞으로 진행방향은 다음과 같다.  
- Week13은 각자 모델을 만들고 가장 좋은 성능을 보인 모델 중심으로 테스트한다.  
[이 글](https://www.notion.so/a941c21d1f8f4b59b80727c3f0fdafe2?v=f95821c075d7433b9795735a9d4663f0)에서 각자 어떤 모델을 실험했는지 기록했다.  
현재 가장 성능이 좋은 모델은 backbone model로 `efficientnet-b2`, decoder로 `DeepLabV3+`이다.  
하지만 `DeepLab`의 실행 시간이 너무 길어서 성능이 약간 떨어지지만 속도가 빠른 `FPN`을 decoder로 사용하기로 했다.  
모든 팀원이 이 모델 중심으로 data augmentation, optimizer, learning rate scheduler, criterion 등을 찾는다.  
먼저 data augmentation과 scheduler에 대해 실험하기로 했다.  
[이 글](https://www.notion.so/b3c9195a66734771b1bf8b5a24cf7059?v=17e2aa0054144949a0f12882c1ccacda)에 각자 실험한 것을 기록하고 있다.  

### trivia
멘탈이 많이 나간게 나의 코드는 강의에서 제공해준 baseline을 참고하여 내 스타일대로 작성했다.  
근데 어디서 문제인지 validation mean IoU와 public mean IoU의 차이가 많이 난다.  
다른 팀원들은 baseline을 기반으로 진행하다 보니 public mean IoU의 차이가 별로 없다.  
사실 지난주부터 차이가 났지만 각자 하다 보니 크게 신경을 쓰지 않았다.  
하지만 이번주부터 다같이 의논하면서 진행하면서 이 부분이 문제가 되었다.  
대회 마감이 얼마 안남았는데 어디서 문제 있는지 모르겠다...  
팀원들에게 도움이 많이 되지 못해서 많이 슬프다...  
