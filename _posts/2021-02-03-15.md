---
title: Week03 Day13
tags:
  - BoostCamp-ai-tech
  - Week03
  - CNN
  - convolution neural network
mathjax: true
---

### convolution network
앞서 convolution layer에 대해 설명했다.  
그 외 부가적인 내용을 설명하겠다.  
fully connected layer는 점점 줄어드는 추세이다.  
왜냐하면 parameter 수가 급격히 증가하여 generalization이 감소하게 된다.  
convolution layer를 깊게 쌓고 fully connected layer를 줄이는 모델이 많이 보인다.  

### 1x1 convolutional layer
1x1 convolutional layer kernel의 width와 height는 각각 1, 1이다.  
보통 kernel은 입력 값의 spatial information을 얻지만 이 경우는 그렇지 못한다.  
그럼 왜 사용할까?  
이 layer는 channel 수를 줄이기 위해 사용된다.  
예를 들어 3x3 convolutional layer로 `11 x 11 x 256`인 입력 값을 `11 x 11 x 128`로 만드려고 한다.  
이때 필요한 parameter의 수는 `3 x 3 x 256 x 128 = 294,912`이다.  
