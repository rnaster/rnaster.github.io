---
title: Week03 Day12
tags:
  - BoostCamp-ai-tech
  - Week03
  - optimization
  - convolution
---

### review: gradient descent
gradient descent는 1계 도함수로 주변 최소값을 찾는 반복적인 최적화 알고리즘이다.  

### optimization
> Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element (with regard to some criterion) from some set of available alternatives.[^1]  

최적화(optimization)는 특정 집합에서 몇가지 기준을 가지고 최고의 요소를 선택하는 것이다.  
보통 최대, 최소인 요소를 찾는다.  
모델을 학습 데이터에 대해 최적화를 한다는 것은 데이터를 잘 설명하도록 parameter를 반복적으로 수정해 나가는 것이다.  
최적화에 대한 몇가지 중요한 개념을 소개한다.  

### generalization
![](/assets/images/5.PNG)  
학습 데이터에 최적화를 할수록 예측 값과 실제 값의 차이가 감소한다.  
하지만 테스트 데이터의 예측 값과 실제 값의 차이는 점점 증가한다.  
학습 데이터에 대한 오차와 테스트 데이터에 대한 오차를 비교했을때 작으면 일반화(generalization)가 잘되는 모델이다.  
즉, 어떤 데이터를 가져와도 학습 데이터의 결과만큼 좋다는 뜻이다.  
일반화가 잘 안되는 경우는 두 데이터의 오차의 차이가 크다.  
이것은 모델이 학습 데이터의 특징을 전부 다 학습했기 때문에 이 데이터와 약간 다른 값이 입력으로 들어오면 큰 차이를 발생시킨다.  
혹은 학습 데이터에 내재되어 있는 오차(noise)까지 학습했기 때문에 테스트 데이터에 대한 성능이 좋게 나오지 못한다.  

### overfitting, underfitting
> In statistics, overfitting is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably".[^2]  

과적합(overfitting)은 과하게 학습한다는 의미로 데이터에 과하게 학습이 되어 향후 미래의 데이터를 예측하는데 잘 하지 못하는 현상을 말한다.  
> Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data.  
An under-fitted model is a model where some parameters or terms that would appear in a correctly specified model are missing.  
Under-fitting would occur, for example, when fitting a linear model to non-linear data.  
Such a model will tend to have poor predictive performance.[^2]  

과소적합(underfitting)은 데이터의 특징(혹은 패턴)을 적절하게 학습하지 못한 현상을 말한다.  
예를 들어 비선형 데이터에 선형모델을 학습할 경우 예측 성능이 안좋은 경향이 보인다.  

### cross validation
교차검증(cross validation)은 테스트 데이터에 얼마나 일반화가 될 것인지 모델 평가하는 방법이다.  
데이터가 많으면 다양한 특징을 가질 수 있으며 일반화된 모델로 학습될 가능성이 높다.  
이런 경우 학습 데이터 대비 테스트 데이터의 성능을 비교하여 일반화 여부를 판단할 수 있을 것이다.  
하지만 학습 데이터가 적은 경우 과적합이 발생할 가능성이 높다.  
여러 모델을 고려하고 그 중 일반화가 가장 좋은 모델을 선택하고 싶다.  

다음은 교차검증 과정을 설명한다.  
<img src="/assets/images/6.png" style="background: white">[^3]  

1. 학습 데이터를 섞은 후 4개의 partition으로 나눈다.  
2. 1번 partition을 제외한 2, 3, 4번 partition으로 모델을 학습한다.  
3. 1번 partition으로 모델의 성능을 확인한다, 이때 모델의 성능을 평가하는 partition을 검정 데이터라 한다.    
4. 2번 partition을 제외한 1, 3, 4번 partition으로 모델을 학습한다.
5. 2번 partition으로 모델의 성능을 확인한다.
6. 3, 4번 partition도 위와 같이 진행한다.
7. 각 partition에 대해 성능을 평가했고 이것들의 평균을 구한다.
8. 다른 모델도 똑같이 하여 비교한다.

- **왜 검정 데이터가 따로 존재하는 걸까? 테스트 데이터를 사용하면 안되나?**  
우선 테스트 데이터는 모델 평가를 위해서만 사용해야 된다.  
학습에 직, 간접적으로 영향을 주어선 안된다.  
어떤 모델을 선택할 것인지, 예를 들어 선형회귀, SVM, random forest 등, learning-rate, batch-size 및 해당 모델에서 요구하는 hyper-parameter 등을 어떻게 선택하느냐에 따라 데이터에 대한 성능이 결정된다.  
처음에는 heuristic search로 모델 및 hyper-parameter 선택을 하고 학습하여 검정 데이터로 성능을 살펴볼 것이다.  
그리고 성능이 좋아지는 방향으로 계속 모델을 수정하며 계속 반복할 것이다.  
`검정 데이터의 성능이 좋아지도록 수정`하는 것은 검정 데이터는 직접적으로 학습에 사용되지 않았지만 간접적으로 학습에 영향을 주는 것이다.  
만약 이 과정에 테스트 데이터를 사용한다면 unseen data에 대해서 이와 똑같은 성능을 보장할 수 없다.  

- **왜 학습 데이터를 여러 개로 나누어서 일부분을 제외하고 모델을 학습시키는 과정을 반복할까?**  
학습과 검정 데이터를 어떻게 나누냐에 따라 모델의 성능이 결정될 것이다.  
그래서 검정 데이터를 바꿔가면서 학습을 시키고 성능을 구하여 그의 평균을 보는게 바람직할 것이다.  
이렇게 하면 결국 모든 학습 데이터를 다 사용하게 된다.  

### bias and variance
추가할 것


[^1]: [위키피디아 - optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)  
[^2]: [위키피디아 - overfitting](https://en.wikipedia.org/wiki/Overfitting)  
[^3]: [위키피디아 - cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))  
