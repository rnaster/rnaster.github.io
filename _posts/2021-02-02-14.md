---
title: Week03 Day12
tags:
  - BoostCamp-ai-tech
  - Week03
  - optimization
  - convolution
---

### review: gradient descent
gradient descent는 1계 도함수로 주변 최소값을 찾는 반복적인 최적화 알고리즘이다.  

### optimization
> Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element (with regard to some criterion) from some set of available alternatives.[^1]  

최적화(optimization)는 특정 집합에서 몇가지 기준을 가지고 최고의 요소를 선택하는 것이다.  
보통 최대, 최소인 요소를 찾는다.  
모델을 학습 데이터에 대해 최적화를 한다는 것은 데이터를 잘 설명하도록 parameter를 반복적으로 수정해 나가는 것이다.  
최적화에 대한 몇가지 중요한 개념을 소개한다.  

### generalization
![](/assets/images/5.PNG)  
학습 데이터에 최적화를 할수록 예측 값과 실제 값의 차이가 감소한다.  
하지만 테스트 데이터의 예측 값과 실제 값의 차이는 점점 증가한다.  
학습 데이터에 대한 오차와 테스트 데이터에 대한 오차를 비교했을때 작으면 일반화(generalization)가 잘되는 모델이다.  
즉, 어떤 데이터를 가져와도 학습 데이터의 결과만큼 좋다는 뜻이다.  
일반화가 잘 안되는 경우는 두 데이터의 오차의 차이가 크다.  
이것은 모델이 학습 데이터의 특징을 전부 다 학습했기 때문에 이 데이터와 약간 다른 값이 입력으로 들어오면 큰 차이를 발생시킨다.  
혹은 학습 데이터에 내재되어 있는 오차(noise)까지 학습했기 때문에 테스트 데이터에 대한 성능이 좋게 나오지 못한다.  

### overfitting, underfitting
> In statistics, overfitting is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably".[^2]  

과적합(overfitting)은 과하게 학습한다는 의미로 데이터에 과하게 학습이 되어 향후 미래의 데이터를 예측하는데 잘 하지 못하는 현상을 말한다.  
> Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data.  
An under-fitted model is a model where some parameters or terms that would appear in a correctly specified model are missing.  
Under-fitting would occur, for example, when fitting a linear model to non-linear data.  
Such a model will tend to have poor predictive performance.[^2]  

과소적합(underfitting)은 데이터의 특징(혹은 패턴)을 적절하게 학습하지 못한 현상을 말한다.  
예를 들어 비선형 데이터에 선형모델을 학습할 경우 예측 성능이 안좋은 경향이 보인다.  

### cross validation
교차검증(cross validation)은 테스트 데이터에 얼마나 일반화가 될 것인지 모델 평가하는 방법이다.  
데이터가 많으면 다양한 특징을 가질 수 있으며 일반화된 모델로 학습될 가능성이 높다.  
이런 경우 학습 데이터 대비 테스트 데이터의 성능을 비교하여 일반화 여부를 판단할 수 있을 것이다.  
하지만 학습 데이터가 적은 경우 과적합이 발생할 가능성이 높다.  
여러 모델을 고려하고 그 중 일반화가 가장 좋은 모델을 선택하고 싶다.  

다음은 교차검증 과정을 설명한다.  
<img src="/assets/images/6.png" style="background: white">[^3]  

1. 학습 데이터를 섞은 후 4개의 partition으로 나눈다.  
2. 1번 partition을 제외한 2, 3, 4번 partition으로 모델을 학습한다.  
3. 1번 partition으로 모델의 성능을 확인한다.  
4. 2번 partition을 제외한 1, 3, 4번 partition으로 모델을 학습한다.
5. 2번 partition으로 모델의 성능을 확인한다.
6. 3, 4번 partition도 위와 같이 진행한다.
7. 각 partition에 대해 성능을 평가했고 이것들의 평균을 구한다.
8. 다른 모델도 똑같이 하여 비교한다.



[^1]: [위키피디아 - optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)  
[^2]: [위키피디아 - overfitting](https://en.wikipedia.org/wiki/Overfitting)  
[^3]: [위키피디아 - cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))  
